"""
Generador de Archivos de Prompts para CompeticiÃ³n de Cartera
=============================================================

Este script genera TODOS los archivos de prompts necesarios.
Ejecuta este cÃ³digo y se crearÃ¡n automÃ¡ticamente los archivos .txt

Uso:
    python generar_prompts.py
"""

import os

# Crear directorio
if not os.path.exists('prompts_competicion'):
    os.makedirs('prompts_competicion')

print("ðŸ“ Generando archivos de prompts...")
print("=" * 60)

# ==================== PROMPT GENERAL ====================
prompt_general = """
# PROMPT GENERAL - OPTIMIZACIÃ“N DE CARTERA PARA COMPETICIÃ“N

## RECURSOS DISPONIBLES

**IMPORTANTE**: Tienes acceso al archivo `Notebook_Ejecutivo_Resumen_Completo.ipynb` que contiene 
TODO el marco teÃ³rico necesario para esta tarea. **LEE ESTE NOTEBOOK PRIMERO** antes de empezar 
a implementar cualquier soluciÃ³n. El notebook contiene:

- TEMA 1: IntroducciÃ³n a Carteras (correlaciÃ³n, diversificaciÃ³n, fÃ³rmulas bÃ¡sicas)
- TEMA 2: Fundamentos de GestiÃ³n de Carteras y Riesgo (Markowitz, CVXPY, Tobin)
- TEMA 3: CAPM y Modelo de Mercado (beta, alpha, SML, regresiÃ³n)
- TEMA 4: Smart Betas y Modelos Multifactoriales (Fama-French, optimizaciÃ³n Top-Down)
- Tabla completa de 41 fÃ³rmulas con explicaciones detalladas
- Ejemplos de cÃ³digo y visualizaciones

---

## CONTEXTO DE LA COMPETICIÃ“N

**Objetivo**: Maximizar el Sharpe Ratio anualizado de una cartera
**MÃ©trica de evaluaciÃ³n**: Sharpe Ratio anualizado sobre retornos futuros no vistos
**Activos disponibles**: 50 activos riesgosos + 1 activo libre de riesgo (renta fija)
**Datos disponibles**: 1761 dÃ­as de retornos logarÃ­tmicos diarios para los 50 activos
**Periodo de competiciÃ³n**: 7 dÃ­as (16-23 enero 2026) donde puedo enviar 1 soluciÃ³n por dÃ­a
**Tasa libre de riesgo**: 2.00% anual

**Restricciones**:
- Long-only: todos los pesos wi â‰¥ 0 (no posiciones cortas)
- Suma de pesos = 1 (inversiÃ³n completa)
- Peso mÃ¡ximo en renta fija: 10% (0.1)
- Sin lÃ­mites individuales por activo riesgoso

**Formato de entrega**: Vector de 50 pesos para los activos riesgosos

---

## MARCO TEÃ“RICO (Consulta el Notebook)

### TEMA 1: Fundamentos
- Rentabilidad: E(RÌƒ_p) = Î£ wáµ¢E(RÌƒáµ¢)
- Varianza: ÏƒÂ²_p = wáµ€Î£w
- Efecto correlaciÃ³n y diversificaciÃ³n

### TEMA 2: Markowitz y Tobin
- max f(w) = wáµ€Î¼ - Î»wáµ€Î£w
- CML: Î¼â‚š = rf + [(Î¼â‚˜ - rf)/Ïƒâ‚˜]Ïƒâ‚š
- ImplementaciÃ³n CVXPY

### TEMA 3: CAPM
- E[rÌƒáµ¢] - rf = Î²áµ¢(E[rÌƒâ‚˜] - rf)
- Î² = Cov(rÌƒáµ¢, rÌƒâ‚˜)/ÏƒÂ²â‚˜

### TEMA 4: Multifactorial
- Fama-French (MKT, SMB, HML, MOM)
- Momentum 12-2
- OptimizaciÃ³n Top-Down

---

## MÃ“DULOS DE TRABAJO

**MÃ“DULO 1**: ExploraciÃ³n y PreparaciÃ³n de Datos
**MÃ“DULO 2**: OptimizaciÃ³n ClÃ¡sica de Markowitz  
**MÃ“DULO 3**: ConstrucciÃ³n de Factores y SeÃ±ales
**MÃ“DULO 4**: OptimizaciÃ³n Multifactorial Avanzada
**MÃ“DULO 5**: ValidaciÃ³n y SelecciÃ³n Final

Consulta los prompts especÃ­ficos de cada mÃ³dulo.

---

## PRINCIPIOS FUNDAMENTALES

1. **Lee el Notebook TeÃ³rico**: Todas las fÃ³rmulas estÃ¡n ahÃ­
2. **Prioriza Robustez**: EvaluaciÃ³n en retornos futuros desconocidos
3. **LibrerÃ­as**: cvxpy, numpy, pandas, matplotlib, seaborn
4. **AnualizaciÃ³n**: Î¼_anual = Î¼_diario Ã— 252, Î£_anual = Î£_diario Ã— 252
5. **CÃ³digo Modular**: Funciones claras con docstrings

---

## VALIDACIONES OBLIGATORIAS

```python
assert all(w >= 0), "Long-only"
assert abs(sum(w) + w_rf - 1.0) < 1e-6, "Suma = 1"
assert 0 <= w_rf <= 0.1, "RF â‰¤ 10%"
assert len(w) == 50, "50 activos"
```

---

## MÃ‰TRICAS A REPORTAR

1. Rentabilidad Esperada Anualizada
2. Volatilidad Esperada Anualizada
3. Sharpe Ratio Anualizado
4. Peso en Renta Fija
5. Ãndice de ConcentraciÃ³n (Herfindahl)
6. NÃºmero de activos con peso >1%

---

**SIGUIENTE PASO**: Lee los prompts modulares especÃ­ficos y el notebook teÃ³rico.
"""

# ==================== MÃ“DULO 1 ====================
modulo1 = """
# MÃ“DULO 1: EXPLORACIÃ“N Y PREPARACIÃ“N DE DATOS

## PREREQUISITO
Lee `Notebook_Ejecutivo_Resumen_Completo.ipynb`:
- ApÃƒÂ©ndice (fÃ³rmulas ID 1-4)
- TEMA 1.1, 1.2, 1.3

## OBJETIVO
Cargar, explorar y preparar datos de 1761 dÃ­as Ã— 50 activos

## PASO 1.1: CARGA
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def cargar_retornos(ruta):
    # Cargar CSV (1761 Ã— 50)
    # Verificar dimensiones, NaNs, infinitos
    pass

retornos = cargar_retornos('retornos_diarios.csv')
```

## PASO 1.2: ESTADÃSTICAS
```python
def calcular_estadisticas_basicas(retornos):
    stats_df = pd.DataFrame({
        'media_diaria': retornos.mean(),
        'std_diaria': retornos.std(),
        'sharpe_historico': retornos.mean() / retornos.std() * np.sqrt(252),
        'media_anual': retornos.mean() * 252,
        'std_anual': retornos.std() * np.sqrt(252)
    })
    return stats_df.sort_values('sharpe_historico', ascending=False)

stats = calcular_estadisticas_basicas(retornos)
print(stats.head(10))
```

## PASO 1.3: CORRELACIONES
```python
corr_matrix = retornos.corr()
mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)
correlaciones = corr_matrix.where(mask).stack()

print(f"CorrelaciÃ³n media: {correlaciones.mean():.4f}")
print(f"CorrelaciÃ³n min/max: {correlaciones.min():.4f} / {correlaciones.max():.4f}")

# Heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, cmap='RdBu_r', center=0, vmin=-1, vmax=1)
plt.title('Matriz de CorrelaciÃ³n')
plt.savefig('correlaciones.png', dpi=300)
```

## PASO 1.4: ANÃLISIS TEMPORAL
```python
# Retornos acumulados
retornos_acum = (1 + retornos).cumprod()
indice_mercado = retornos.mean(axis=1)

# Volatilidad rolling 63 dÃ­as
vol_rolling = retornos.rolling(63).std() * np.sqrt(252)
```

## PASO 1.5: PREPARACIÃ“N FINAL
```python
class PreparadorDatos:
    def __init__(self, retornos, rf_anual=0.02):
        self.retornos = retornos
        self.rf_anual = rf_anual
        self.rf_diario = (1 + rf_anual)**(1/252) - 1
    
    def calcular_estadisticas(self, ventana=None):
        datos = self.retornos if ventana is None else self.retornos.iloc[-ventana:]
        self.mu_diario = datos.mean().values
        self.cov_matriz = datos.cov().values
        self.mu_anual = self.mu_diario * 252
        self.cov_anual = self.cov_matriz * 252
        return self

preparador = PreparadorDatos(retornos)
preparador.calcular_estadisticas()
mu, Sigma = preparador.mu_anual, preparador.cov_anual
```

## SALIDAS
âœ… DataFrame retornos cargado
âœ… EstadÃ­sticas completas
âœ… Matriz correlaciones
âœ… Vectores Î¼ y Î£ anualizados
âœ… GrÃ¡ficos guardados

**SIGUIENTE**: MÃ³dulo 2 - Markowitz
"""

# ==================== MÃ“DULO 2 ====================
modulo2 = """
# MÃ“DULO 2: OPTIMIZACIÃ“N DE MARKOWITZ

## PREREQUISITO
Lee Notebook: TEMA 2.1, 2.3, 2.4, 2.6
FÃ³rmulas ID 14-16, 28

## OBJETIVO
OptimizaciÃ³n clÃ¡sica + mÃ¡ximo Sharpe + frontera eficiente

## PASO 2.1: MARKOWITZ CON Î»
```python
import cvxpy as cp

def optimizar_markowitz_lambda(mu, Sigma, rf, lambda_param):
    n = len(mu)
    w = cp.Variable(n)
    w_rf = cp.Variable()
    
    rentabilidad = w @ mu + w_rf * rf
    riesgo = cp.quad_form(w, Sigma)
    objetivo = rentabilidad - lambda_param * riesgo
    
    restricciones = [
        cp.sum(w) + w_rf == 1,
        w >= 0,
        w_rf >= 0,
        w_rf <= 0.1
    ]
    
    problema = cp.Problem(cp.Maximize(objetivo), restricciones)
    problema.solve(solver=cp.ECOS)
    
    w_opt = w.value
    w_rf_opt = w_rf.value
    mu_p = w_opt @ mu + w_rf_opt * rf
    sigma_p = np.sqrt(w_opt @ Sigma @ w_opt)
    sharpe = (mu_p - rf) / sigma_p
    
    return {'w': w_opt, 'w_rf': w_rf_opt, 'sharpe': sharpe}

# Probar diferentes Î»
for lam in [0.5, 1.0, 2.0, 5.0]:
    res = optimizar_markowitz_lambda(mu, Sigma, rf, lam)
    print(f"Î»={lam}: Sharpe={res['sharpe']:.4f}")
```

## PASO 2.2: MÃXIMO SHARPE DIRECTO
```python
def optimizar_sharpe_maximo(mu, Sigma, rf):
    n = len(mu)
    y = cp.Variable(n)
    y_rf = cp.Variable()
    
    objetivo = cp.quad_form(y, Sigma)
    restricciones = [
        y @ mu + y_rf * rf == 1,
        y >= 0,
        y_rf >= 0
    ]
    
    problema = cp.Problem(cp.Minimize(objetivo), restricciones)
    problema.solve()
    
    suma = np.sum(y.value) + y_rf.value
    w_opt = y.value / suma
    w_rf_opt = y_rf.value / suma
    
    # Ajustar si w_rf > 0.1
    if w_rf_opt > 0.1:
        w_rf_opt = 0.1
        w_opt = w_opt * (1 - w_rf_opt) / np.sum(w_opt)
    
    mu_p = w_opt @ mu + w_rf_opt * rf
    sigma_p = np.sqrt(w_opt @ Sigma @ w_opt)
    sharpe = (mu_p - rf) / sigma_p
    
    return {'w': w_opt, 'w_rf': w_rf_opt, 'sharpe': sharpe,
            'rentabilidad': mu_p, 'volatilidad': sigma_p}

cartera_max_sharpe = optimizar_sharpe_maximo(mu, Sigma, rf)
print(f"MÃ¡ximo Sharpe: {cartera_max_sharpe['sharpe']:.4f}")
```

## PASO 2.3: FRONTERA EFICIENTE
```python
def construir_frontera(mu, Sigma, rf, n_puntos=50):
    mu_min = rf
    mu_max = mu.max() * 0.95
    mu_targets = np.linspace(mu_min, mu_max, n_puntos)
    
    fronteras = []
    for mu_t in mu_targets:
        w = cp.Variable(len(mu))
        w_rf = cp.Variable()
        
        objetivo = cp.quad_form(w, Sigma)
        restricciones = [
            w @ mu + w_rf * rf == mu_t,
            cp.sum(w) + w_rf == 1,
            w >= 0,
            w_rf >= 0,
            w_rf <= 0.1
        ]
        
        problema = cp.Problem(cp.Minimize(objetivo), restricciones)
        problema.solve(verbose=False)
        
        if problema.status == 'optimal':
            sigma_p = np.sqrt(objetivo.value)
            fronteras.append({
                'rentabilidad': mu_t,
                'volatilidad': sigma_p,
                'sharpe': (mu_t - rf) / sigma_p
            })
    
    return pd.DataFrame(fronteras)

frontera_df = construir_frontera(mu, Sigma, rf)

# Graficar
plt.figure(figsize=(12, 8))
plt.plot(frontera_df['volatilidad']*100, frontera_df['rentabilidad']*100, 'b-', lw=2)
plt.scatter(cartera_max_sharpe['volatilidad']*100, 
            cartera_max_sharpe['rentabilidad']*100,
            s=200, c='red', marker='*', label='Max Sharpe')
plt.xlabel('Volatilidad (%)')
plt.ylabel('Rentabilidad (%)')
plt.title('Frontera Eficiente')
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig('frontera_eficiente.png', dpi=300)
```

## PASO 2.4: ANÃLISIS DE SENSIBILIDAD
```python
# Ventanas temporales
ventanas = [252, 504, 756, None]
resultados = []

for ventana in ventanas:
    if ventana:
        mu_v = retornos.iloc[-ventana:].mean().values * 252
        Sigma_v = retornos.iloc[-ventana:].cov().values * 252
    else:
        mu_v, Sigma_v = mu, Sigma
    
    cartera = optimizar_sharpe_maximo(mu_v, Sigma_v, rf)
    resultados.append({
        'ventana': ventana or 'Completa',
        'sharpe': cartera['sharpe'],
        'concentracion': np.sum(cartera['w']**2)
    })

pd.DataFrame(resultados)
```

## SALIDAS
âœ… Cartera Ã³ptima con diferentes Î»
âœ… Cartera mÃ¡ximo Sharpe
âœ… Frontera eficiente completa
âœ… AnÃ¡lisis de sensibilidad
âœ… CML visualizada

**SIGUIENTE**: MÃ³dulo 3 - Factores
"""

# ==================== MÃ“DULO 3 ====================
modulo3 = """
# MÃ“DULO 3: CONSTRUCCIÃ“N DE FACTORES Y SEÃ‘ALES

## PREREQUISITO
Lee Notebook: TEMA 4.1, 4.3
FÃ³rmulas ID 35-40

## OBJETIVO
Construir seÃ±ales de momentum, volatilidad, beta

## PASO 3.1: MOMENTUM 12-2
```python
def calcular_momentum_12_2(retornos):
    \"\"\"
    MOM = âˆ(j=2 to 12)(1 + r_{t-j}) - 1
    En dÃ­as: retornos acumulados desde t-252 hasta t-21
    \"\"\"
    momentum = pd.DataFrame(index=retornos.index, columns=retornos.columns)
    
    for i in range(252, len(retornos)):
        # Retornos de t-252 a t-21 (evitar t-1 por reversiÃ³n)
        ret_periodo = retornos.iloc[i-252:i-21]
        mom = (1 + ret_periodo).prod() - 1
        momentum.iloc[i] = mom
    
    return momentum

momentum = calcular_momentum_12_2(retornos)

# Momentum mÃ¡s reciente (Ãºltima fila vÃ¡lida)
mom_actual = momentum.iloc[-1]
print("Top 10 por Momentum:")
print(mom_actual.sort_values(ascending=False).head(10))
```

## PASO 3.2: VOLATILIDAD ROLLING
```python
def calcular_volatilidad_rolling(retornos, ventanas=[21, 63, 252]):
    \"\"\"
    Calcular volatilidad en mÃºltiples ventanas
    \"\"\"
    vols = {}
    for v in ventanas:
        vols[f'vol_{v}d'] = retornos.rolling(v).std() * np.sqrt(252)
    
    return pd.DataFrame(vols, index=retornos.index)

volatilidades = calcular_volatilidad_rolling(retornos)

# Volatilidad mÃ¡s reciente
vol_actual_63d = volatilidades['vol_63d'].iloc[-1]
print("Top 10 Menor Volatilidad (63d):")
print(vol_actual_63d.sort_values().head(10))
```

## PASO 3.3: BETA VS MERCADO
```python
def calcular_betas(retornos, ventana=252):
    \"\"\"
    Î² = Cov(r_i, r_M) / Var(r_M)
    Mercado = Ã­ndice equiponderado de 50 activos
    \"\"\"
    # Ãndice mercado equiponderado
    indice_mercado = retornos.mean(axis=1)
    
    betas = {}
    for col in retornos.columns:
        # Usar Ãºltimos 'ventana' dÃ­as
        datos = retornos[[col]].iloc[-ventana:]
        mercado = indice_mercado.iloc[-ventana:]
        
        cov = np.cov(datos[col], mercado)[0, 1]
        var_m = np.var(mercado)
        beta = cov / var_m if var_m > 0 else 1.0
        betas[col] = beta
    
    return pd.Series(betas)

betas = calcular_betas(retornos, ventana=252)
print("Top 10 Menor Beta:")
print(betas.sort_values().head(10))
```

## PASO 3.4: NORMALIZACIÃ“N Z-SCORE
```python
def normalizar_senales(senales_dict):
    \"\"\"
    z = (seÃ±al - Î¼) / Ïƒ
    NormalizaciÃ³n cross-sectional
    \"\"\"
    senales_norm = {}
    
    for nombre, senal in senales_dict.items():
        if isinstance(senal, pd.Series):
            # Ãšltima observaciÃ³n vÃ¡lida
            valores = senal.dropna()
        else:
            valores = senal
        
        mu = valores.mean()
        sigma = valores.std()
        z = (valores - mu) / sigma if sigma > 0 else valores * 0
        senales_norm[nombre] = z
    
    return pd.DataFrame(senales_norm)

# SeÃ±ales actuales
senales = {
    'momentum': mom_actual,
    'vol_63d': -vol_actual_63d,  # Negativo porque queremos baja vol
    'beta': -betas,  # Negativo para favorecer baja beta
    'sharpe_hist': stats['sharpe_historico']
}

senales_norm = normalizar_senales(senales)
print(senales_norm.head())
```

## PASO 3.5: CONSTRUCCIÃ“N MATRIZ X
```python
def construir_matriz_caracteristicas(senales_norm):
    \"\"\"
    Matriz X (50 Ã— K) de caracterÃ­sticas normalizadas
    Cada fila = activo, cada columna = factor
    \"\"\"
    X = senales_norm.values  # (50, K)
    nombres_factores = senales_norm.columns.tolist()
    
    print(f"Matriz X shape: {X.shape}")
    print(f"Factores: {nombres_factores}")
    
    return X, nombres_factores

X, nombres_factores = construir_matriz_caracteristicas(senales_norm)

# Verificar
print(f"\\nCaracterÃ­sticas de X:")
print(f"  Media por columna: {X.mean(axis=0)}")  # Debe ser ~0
print(f"  Std por columna: {X.std(axis=0)}")     # Debe ser ~1
```

## PASO 3.6: RANKING MULTIFACTORIAL
```python
def crear_ranking_multifactorial(senales_norm, pesos_factores=None):
    \"\"\"
    Combinar seÃ±ales en ranking Ãºnico
    Score = Î£ peso_k Ã— z_k
    \"\"\"
    if pesos_factores is None:
        # Pesos iguales por defecto
        pesos_factores = {col: 1.0 for col in senales_norm.columns}
    
    score_total = pd.Series(0, index=senales_norm.index)
    for factor, peso in pesos_factores.items():
        if factor in senales_norm.columns:
            score_total += peso * senales_norm[factor]
    
    # Normalizar score total
    score_total = (score_total - score_total.mean()) / score_total.std()
    
    return score_total.sort_values(ascending=False)

# Ranking con pesos iguales
ranking = crear_ranking_multifactorial(senales_norm)
print("Top 20 por Ranking Multifactorial:")
print(ranking.head(20))
```

## SALIDAS
âœ… SeÃ±ales de momentum calculadas
âœ… Volatilidades rolling
âœ… Betas vs mercado
âœ… SeÃ±ales normalizadas (z-scores)
âœ… Matriz X (50 Ã— K)
âœ… Ranking multifactorial

**SIGUIENTE**: MÃ³dulo 4 - OptimizaciÃ³n Avanzada
"""

# ==================== MÃ“DULO 4 ====================
modulo4 = """
# MÃ“DULO 4: OPTIMIZACIÃ“N MULTIFACTORIAL AVANZADA

## PREREQUISITO
Lee Notebook: TEMA 4.3 (OptimizaciÃ³n Top-Down)
FÃ³rmulas ID 37-41

## OBJETIVO
OptimizaciÃ³n Top-Down con tracking de exposiciones

## PASO 4.1: DEFINIR EXPOSICIONES OBJETIVO
```python
# Exposiciones objetivo b*
exposiciones_objetivo = {
    'momentum': 0.5,      # Alta exposiciÃ³n a momentum
    'vol_63d': -0.3,      # Baja volatilidad
    'beta': 0.0,          # Neutral a beta (market neutral)
    'sharpe_hist': 0.4    # Alta exposiciÃ³n a Sharpe histÃ³rico
}

b_star = np.array([exposiciones_objetivo[f] for f in nombres_factores])
print("Exposiciones objetivo b*:", b_star)
```

## PASO 4.2: PESOS DE EXPOSICIÃ“N
```python
# Pesos W_k para cada factor
# OpciÃ³n 1: Pesos iguales
W_k_uniform = np.ones(len(nombres_factores))

# OpciÃ³n 2: Inverso de varianza
W_k_invvar = 1 / X.std(axis=0)**2
W_k_invvar = W_k_invvar / W_k_invvar.sum() * len(nombres_factores)  # Normalizar

print("Pesos de factores (inv-var):", dict(zip(nombres_factores, W_k_invvar)))
```

## PASO 4.3: OPTIMIZACIÃ“N TOP-DOWN
```python
def optimizar_topdown(mu, Sigma, rf, X, b_star, W_k,
                       lambda_riesgo=1.0, tau_rotacion=0.1, w_prev=None):
    \"\"\"
    min ||X^T w - b*||Â²_W + Î» w^T Î£ w + Ï„ ||w - w_prev||Â²
    
    s.t. sum(w) + w_rf = 1
         w â‰¥ 0
         0 â‰¤ w_rf â‰¤ 0.1
    \"\"\"
    n, K = X.shape
    
    # Variables
    w = cp.Variable(n)
    w_rf = cp.Variable()
    
    # TÃ©rmino 1: Tracking de exposiciones
    # (X^T w - b*)^T W (X^T w - b*)
    exposicion = X.T @ w  # (K,)
    desviacion = exposicion - b_star
    W_matriz = np.diag(W_k)
    tracking = cp.quad_form(desviacion, W_matriz)
    
    # TÃ©rmino 2: PenalizaciÃ³n por riesgo
    riesgo = cp.quad_form(w, Sigma)
    
    # TÃ©rmino 3: PenalizaciÃ³n por rotaciÃ³n
    if w_prev is None:
        w_prev = np.ones(n) / n  # Equiponderada inicial
    rotacion = cp.sum_squares(w - w_prev)
    
    # FunciÃ³n objetivo
    objetivo = tracking + lambda_riesgo * riesgo + tau_rotacion * rotacion
    
    # Restricciones
    restricciones = [
        cp.sum(w) + w_rf == 1,
        w >= 0,
        w_rf >= 0,
        w_rf <= 0.1
    ]
    
    # Resolver
    problema = cp.Problem(cp.Minimize(objetivo), restricciones)
    problema.solve(solver=cp.ECOS)
    
    if problema.status != 'optimal':
        print(f"âš ï¸ Status: {problema.status}")
        return None
    
    # Calcular mÃ©tricas
    w_opt = w.value
    w_rf_opt = w_rf.value
    mu_p = w_opt @ mu + w_rf_opt * rf
    sigma_p = np.sqrt(w_opt @ Sigma @ w_opt)
    sharpe_p = (mu_p - rf) / sigma_p
    
    # Exposiciones reales
    exposiciones_reales = X.T @ w_opt
    
    return {
        'w': w_opt,
        'w_rf': w_rf_opt,
        'rentabilidad': mu_p,
        'volatilidad': sigma_p,
        'sharpe': sharpe_p,
        'exposiciones_reales': exposiciones_reales,
        'exposiciones_objetivo': b_star,
        'tracking_error': np.sum((exposiciones_reales - b_star)**2)
    }

# Optimizar
cartera_topdown = optimizar_topdown(
    mu, Sigma, rf, X, b_star, W_k_invvar,
    lambda_riesgo=2.0, tau_rotacion=0.5
)

print(f"\\nCartera Top-Down:")
print(f"  Sharpe: {cartera_topdown['sharpe']:.4f}")
print(f"  Tracking Error: {cartera_topdown['tracking_error']:.4f}")
print(f"\\n  Exposiciones:")
for i, nombre in enumerate(nombres_factores):
    print(f"    {nombre:15s}: objetivo={b_star[i]:6.2f}, real={cartera_topdown['exposiciones_reales'][i]:6.2f}")
```

## PASO 4.4: ESTRATEGIAS ALTERNATIVAS
```python
# Estrategia 1: High Momentum + Low Vol
exp_mom_lowvol = b_star.copy()
exp_mom_lowvol[nombres_factores.index('momentum')] = 0.7
exp_mom_lowvol[nombres_factores.index('vol_63d')] = -0.5

cart_mom_lowvol = optimizar_topdown(mu, Sigma, rf, X, exp_mom_lowvol, W_k_invvar)

# Estrategia 2: Quality (high Sharpe)
exp_quality = np.zeros(len(nombres_factores))
exp_quality[nombres_factores.index('sharpe_hist')] = 0.8

cart_quality = optimizar_topdown(mu, Sigma, rf, X, exp_quality, W_k_invvar)

# Estrategia 3: Minimum Variance (solo penalizar riesgo)
cart_minvar = optimizar_topdown(mu, Sigma, rf, X, 
                                  np.zeros(len(nombres_factores)), W_k_invvar,
                                  lambda_riesgo=10.0, tau_rotacion=0.1)

# Comparar
print("\\n=== COMPARACIÃ“N DE ESTRATEGIAS ===")
estrategias = {
    'Max Sharpe (Markowitz)': cartera_max_sharpe,
    'Top-Down Multifactorial': cartera_topdown,
    'High Mom + Low Vol': cart_mom_lowvol,
    'Quality': cart_quality,
    'Min Variance': cart_minvar
}

for nombre, cart in estrategias.items():
    print(f"\\n{nombre}:")
    print(f"  Sharpe: {cart['sharpe']:.4f}")
    print(f"  Ret: {cart['rentabilidad'